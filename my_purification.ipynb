{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSgvF41KfYZX",
        "outputId": "f90a00ca-c942-4d8e-f5ed-215b21669e48"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from model.nn_model import VAEClassifier, StAEClassifier\n",
        "from pgd_purify import vae_purify, stae_purify, pgd_linf\n",
        "\n",
        "batch_size=1024\n",
        "num_visualize = 12\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "vae_classifier = VAEClassifier()\n",
        "stae_classifier = StAEClassifier()\n",
        "vae_classifier.load_state_dict(torch.load('./model/vae_clf.pth', map_location=torch.device('cpu')))\n",
        "stae_classifier.load_state_dict(torch.load('./model/stae_clf.pth', map_location=torch.device('cpu')))\n",
        "vae_classifier = vae_classifier.to(device)\n",
        "stae_classifier = stae_classifier.to(device)\n",
        "vae_classifier = vae_classifier.eval()\n",
        "stae_classifier = stae_classifier.eval()\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])), batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "def pred2label(y_pred_vae, y_pred_stae, labels):\n",
        "    label_name = np.array(['top', 'trouser', 'pullover', 'dress', 'coat',\n",
        "                           'sandal', 'shirt', 'sneaker', 'bag', 'ank boot'])\n",
        "    gt = labels.detach().cpu().numpy()\n",
        "    pred_vae = y_pred_vae.argmax(-1).cpu().detach().numpy()\n",
        "    pred_stae = y_pred_stae.argmax(-1).cpu().detach().numpy()\n",
        "    label_selected = label_name[gt]\n",
        "    vae_pred = label_name[pred_vae]\n",
        "    stae_pred = label_name[pred_stae]\n",
        "    print('Accuracy of the selected batch')\n",
        "    acc_vae = np.sum(np.array(gt) == np.array(pred_vae)) / len(gt)\n",
        "    acc_stae = np.sum(np.array(gt) == np.array(pred_stae)) / len(gt)\n",
        "    print('Accuracy of Standard-AE-Classifier:', acc_stae)\n",
        "    print('Accuracy of VAE-Classifier:', acc_vae)\n",
        "    return label_selected, vae_pred, stae_pred\n",
        "\n",
        "\n",
        "def top_k_vis(num_visualize, images, x_reconst_vae, x_reconst_stae):\n",
        "    input_img = images[:num_visualize,0].detach().cpu().numpy()\n",
        "    vae_reconst = x_reconst_vae[:num_visualize,0].detach().cpu().numpy()\n",
        "    stae_reconst = x_reconst_stae[:num_visualize,0].detach().cpu().numpy()\n",
        "    input_sample = np.concatenate(input_img, axis=1)\n",
        "    reconst_vae = np.concatenate(vae_reconst, axis=1)\n",
        "    reconst_stae = np.concatenate(stae_reconst, axis=1)\n",
        "    return input_sample, reconst_vae, reconst_stae\n",
        "\n",
        "gt_label = []\n",
        "stae_pred = []\n",
        "vae_pred = []\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\n",
        "    images, labels = data.to(device), target.to(device)\n",
        "    with torch.no_grad():\n",
        "        x_reconst_vae, z, y_pred_vae, mu, log_var = vae_classifier(images, deterministic=True,\n",
        "                                                                   classification_only=False)\n",
        "        x_reconst_stae, z, y_pred_stae = stae_classifier(images, classification_only=False)\n",
        "\n",
        "    break\n",
        "\n",
        "label_selected, vae_pred, stae_pred = pred2label(y_pred_vae, y_pred_stae, labels)\n",
        "input_sample, reconst_vae, reconst_stae = top_k_vis(num_visualize, images, x_reconst_vae, x_reconst_stae)\n",
        "\n",
        "adv_vae = pgd_linf(images, labels, vae_classifier, atk_itr=200, eps=50/255, alpha=2/255, device=device)\n",
        "adv_stae = pgd_linf(images, labels, stae_classifier, atk_itr=200, eps=50/255, alpha=2/255, device=device)\n",
        "\n",
        "torch.save(adv_vae, './adv_vae.pt')\n",
        "torch.save(adv_stae, './adv_stae.pt')\n",
        "\n",
        "# if you don't want to train the adversarial samples again in order to save time, you can use these codes where adv samples have been saved\n",
        "'''\n",
        "adv_vae = torch.load('./adv_vae.pt', map_location=device)\n",
        "adv_stae = torch.load('./adv_stae.pt', map_location=device)\n",
        "'''\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_reconst_vae, z, y_pred_vae, mu, log_var = vae_classifier(adv_vae, deterministic=True, classification_only=False)\n",
        "    x_reconst_stae, z, y_pred_stae = stae_classifier(adv_stae, classification_only=False)\n",
        "\n",
        "label_selected, vae_pred, stae_pred = pred2label(y_pred_vae, y_pred_stae, labels)\n",
        "input_adv_sample_vae, reconst_vae, _ = top_k_vis(num_visualize, adv_vae, x_reconst_vae, x_reconst_stae)\n",
        "input_adv_sample_stae, _, reconst_stae = top_k_vis(num_visualize, adv_stae, x_reconst_vae, x_reconst_stae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBMyyGE6SRqL"
      },
      "source": [
        "# MagNet ConvAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOEgiKFwharI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvAutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 7)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 7),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8-EfyZKhc2D",
        "outputId": "f8c44721-c5ea-4175-9715-b0abf557bc11"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjcGwLj1gX_Y",
        "outputId": "20962f54-613c-4164-8fae-eada7ac8cd95"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_ae(model, data_loader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()\n",
        "    print(f\"begin trainning {model.__class__.__name__}...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for data in pbar:\n",
        "            images, _ = data\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({\"Loss\": f\"{loss.item():.6f}\"})\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    print(\"Completed\")\n",
        "\n",
        "print(\"=\"*30)\n",
        "detector_ae = ConvAutoEncoder().to(device)\n",
        "criterion_detector = nn.MSELoss()\n",
        "optimizer_detector = optim.Adam(detector_ae.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "train_ae(detector_ae, train_loader, criterion_detector, optimizer_detector, num_epochs=50)\n",
        "torch.save(detector_ae.state_dict(), './detector_ae.pth')\n",
        "print(\"Detector AE has been saved detector_ae.pth\")\n",
        "\n",
        "\n",
        "print(\"=\"*30)\n",
        "reformer_ae = ConvAutoEncoder().to(device)\n",
        "criterion_reformer = nn.L1Loss()\n",
        "optimizer_reformer = optim.Adam(reformer_ae.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "train_ae(reformer_ae, train_loader, criterion_reformer, optimizer_reformer, num_epochs=50)\n",
        "torch.save(reformer_ae.state_dict(), './reformer_ae.pth')\n",
        "print(\"Reformer AE has been saved reformer_ae.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv_ZPMGmhnj5"
      },
      "outputs": [],
      "source": [
        "detector_ae = ConvAutoEncoder().to(device)\n",
        "detector_ae.load_state_dict(torch.load('./detector_ae.pth', map_location=device))\n",
        "detector_ae.eval()\n",
        "\n",
        "reformer_ae = ConvAutoEncoder().to(device)\n",
        "reformer_ae.load_state_dict(torch.load('./reformer_ae.pth', map_location=device))\n",
        "reformer_ae.eval()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def magnet_purify_pytorch(adv_data, threshold=0.001, device=None):\n",
        "    data_in = adv_data.to(device)\n",
        "    reconstructed = detector_ae(data_in)\n",
        "    rec_error = torch.mean((data_in - reconstructed)**2, dim=(1, 2, 3))\n",
        "    mask_adv = rec_error > threshold\n",
        "    purify_data = data_in.clone()\n",
        "    if torch.any(mask_adv):\n",
        "        purified = reformer_ae(data_in[mask_adv])\n",
        "        purify_data[mask_adv] = purified\n",
        "    return purify_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7CYXSXSTdR",
        "outputId": "05ce330d-32a2-476d-c493-89bc0007f29e"
      },
      "outputs": [],
      "source": [
        "\n",
        "BEST_THRESHOLD_VAE = 0.00001\n",
        "\n",
        "BEST_THRESHOLD_STAE = 0.00788\n",
        "\n",
        "\n",
        "_, labels = next(iter(test_loader))\n",
        "labels = labels.to(device)\n",
        "\n",
        "\n",
        "purify_data_vae = magnet_purify_pytorch(adv_vae, threshold=BEST_THRESHOLD_VAE, device=device)\n",
        "purify_data_stae = magnet_purify_pytorch(adv_stae, threshold=BEST_THRESHOLD_STAE, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_reconst_vae, z, y_pred_vae, mu, log_var = vae_classifier(purify_data_vae, deterministic=True, classification_only=False)\n",
        "    x_reconst_stae, z, y_pred_stae = stae_classifier(purify_data_stae, classification_only=False)\n",
        "\n",
        "label_selected, vae_pred, stae_pred = pred2label(y_pred_vae, y_pred_stae, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxsKrsrLsLCv"
      },
      "source": [
        "# ConvAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x8ktPoNsNxy",
        "outputId": "0d329bd6-3f0c-4511-de39-9459a7c1132f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "reformer_ae = ConvAutoEncoder().to(device)\n",
        "reformer_ae.load_state_dict(torch.load('./reformer_ae.pth', map_location=device))\n",
        "reformer_ae.eval()\n",
        "\n",
        "def reformer_purify(adv_data, reformer_model, device=None):\n",
        "    data_in = adv_data.to(device)\n",
        "    purified_data = reformer_model(data_in)\n",
        "    return purified_data\n",
        "\n",
        "purify_data_vae = reformer_purify(adv_vae, reformer_ae, device=device)\n",
        "purify_data_stae = reformer_purify(adv_stae, reformer_ae, device=device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_reconst_vae, z, y_pred_vae, mu, log_var = vae_classifier(purify_data_vae, deterministic=True, classification_only=False)\n",
        "    x_reconst_stae, z, y_pred_stae = stae_classifier(purify_data_stae, classification_only=False)\n",
        "\n",
        "label_selected, vae_pred, stae_pred = pred2label(y_pred_vae, y_pred_stae, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2xAwFwtgHUn"
      },
      "source": [
        "# DAE-Recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dae_purify(data, model, atk_itr=100, eps=0.2, alpha=1/255, random_iteration=1, device=None):\n",
        "\n",
        "    purified_data = data.clone().detach().to(device)\n",
        "\n",
        "    for _ in range(random_iteration):\n",
        "        delta = torch.zeros_like(purified_data, requires_grad=True).to(device)\n",
        "\n",
        "        for i in range(atk_itr):\n",
        "            model.zero_grad()\n",
        "            try:\n",
        "                x_reconst, *rest = model(purified_data + delta, deterministic=False, classification_only=False)\n",
        "            except TypeError:\n",
        "                x_reconst, *rest = model(purified_data + delta, classification_only=False)\n",
        "            loss = torch.sum((x_reconst - purified_data - delta) ** 2)\n",
        "            loss.backward()\n",
        "            delta.data = delta.data - alpha * torch.sign(delta.grad.data)\n",
        "            delta.data = torch.clamp(delta.data, -eps, eps)\n",
        "            delta.data = torch.clamp(purified_data + delta.data, 0, 1) - purified_data\n",
        "            delta.grad.zero_()\n",
        "\n",
        "        purified_data = purified_data + delta.detach()\n",
        "        purified_data = torch.clamp(purified_data, 0, 1)\n",
        "\n",
        "    return purified_data\n",
        "\n",
        "\n",
        "purify_data_vae = dae_purify(adv_vae, vae_classifier, atk_itr=100, eps=50/255, random_iteration=1, device=device)\n",
        "purify_data_stae = dae_purify(adv_stae, stae_classifier, atk_itr=100, eps=50/255, random_iteration=1, device=device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_reconst_vae, z, y_pred_vae, mu, log_var = vae_classifier(purify_data_vae, deterministic=True, classification_only=False)\n",
        "    x_reconst_stae, z, y_pred_stae = stae_classifier(purify_data_stae, classification_only=False)\n",
        "\n",
        "label_selected, vae_pred, stae_pred = pred2label(y_pred_vae, y_pred_stae, labels)\n",
        "input_pfy_sample_vae, reconst_vae, _ = top_k_vis(num_visualize, purify_data_vae, x_reconst_vae, x_reconst_stae)\n",
        "input_pfy_sample_stae, _, reconst_stae = top_k_vis(num_visualize, purify_data_stae, x_reconst_vae, x_reconst_stae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
