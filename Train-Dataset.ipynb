{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f9c303",
   "metadata": {},
   "source": [
    "# Training codes summary for datasets and Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/DL')\n",
    "# save your nn_model in the certain path\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "# epoch_num = 100 \n",
    "classification_weight = 8\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7700a91",
   "metadata": {},
   "source": [
    "## Training on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2099fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model import VAEClassifier, StAEClassifier\n",
    "epoch_num = 100\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])), batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_classifier = VAEClassifier()\n",
    "stae_classifier = StAEClassifier()\n",
    "vae_classifier = VAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "stae_classifier = StAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "\n",
    "CE_Loss = nn.CrossEntropyLoss()\n",
    "mseloss = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(vae_classifier.parameters(), lr=lr)\n",
    "optimizer2 = torch.optim.Adam(stae_classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd62f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "for epoch in range(epoch_num):\n",
    "    vae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y, mu, log_var = vae_classifier(data, deterministic=False, classification_only=False)\n",
    "        recons_loss = torch.sum((x_reconst - data) ** 2)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp()) \n",
    "        # jointly training\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + recons_loss + kld_loss \n",
    "        optimizer1.zero_grad() \n",
    "        loss_val.backward() \n",
    "        optimizer1.step() \n",
    "\n",
    "vae_classifier.eval()\n",
    "torch.save(vae_classifier.state_dict(), './fmnist_vae_clf.pth')\n",
    "# St-AE\n",
    "for epoch in range(epoch_num):\n",
    "    stae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y = stae_classifier(data, classification_only=False)\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + torch.sum((x_reconst - data) ** 2)\n",
    "        optimizer2.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "stae_classifier.eval()\n",
    "torch.save(stae_classifier.state_dict(), './fmnist_stae_clf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_classifier = vae_classifier.eval()\n",
    "stae_classifier = stae_classifier.eval()\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),])), batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# St-AE\n",
    "pred_list = []\n",
    "gt_list = [] # ground truth\n",
    "for batch_idx, (data, target) in enumerate(test_loader): \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test = stae_classifier(data, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample = np.concatenate(x_reconst[:10,0].detach().cpu().numpy(), axis=1)\n",
    "input_sample = np.concatenate(data[:10,0].detach().cpu().numpy(), axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0), cmap='gray')\n",
    "plt.show()\n",
    "# VAE\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test, mu, log_var = vae_classifier(data, deterministic=True, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample = np.concatenate(x_reconst[:10,0].detach().cpu().numpy(), axis=1)\n",
    "input_sample = np.concatenate(data[:10,0].detach().cpu().numpy(), axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4e109",
   "metadata": {},
   "source": [
    "## Training on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model import VAEClassifier, StAEClassifier\n",
    "epoch_num = 100\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])), batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce442b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_classifier = VAEClassifier()\n",
    "stae_classifier = StAEClassifier()\n",
    "vae_classifier = VAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "stae_classifier = StAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "\n",
    "CE_Loss = nn.CrossEntropyLoss()\n",
    "mseloss = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(vae_classifier.parameters(), lr=lr)\n",
    "optimizer2 = torch.optim.Adam(stae_classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "for epoch in range(epoch_num):\n",
    "    vae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y, mu, log_var = vae_classifier(data, deterministic=False, classification_only=False)\n",
    "        recons_loss = torch.sum((x_reconst - data) ** 2)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp()) \n",
    "        # jointly training\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + recons_loss + kld_loss \n",
    "        optimizer1.zero_grad() \n",
    "        loss_val.backward() \n",
    "        optimizer1.step() \n",
    "\n",
    "vae_classifier.eval()\n",
    "torch.save(vae_classifier.state_dict(), './mnist_vae_clf.pth')\n",
    "# St-AE\n",
    "for epoch in range(epoch_num):\n",
    "    stae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y = stae_classifier(data, classification_only=False)\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + torch.sum((x_reconst - data) ** 2)\n",
    "        optimizer2.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "stae_classifier.eval()\n",
    "torch.save(stae_classifier.state_dict(), './mnist_stae_clf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])), batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# St-AE\n",
    "pred_list = []\n",
    "gt_list = [] # ground truth\n",
    "for batch_idx, (data, target) in enumerate(test_loader): \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test = stae_classifier(data, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample = np.concatenate(x_reconst[:10,0].detach().cpu().numpy(), axis=1)\n",
    "input_sample = np.concatenate(data[:10,0].detach().cpu().numpy(), axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0), cmap='gray')\n",
    "plt.show()\n",
    "# VAE\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test, mu, log_var = vae_classifier(data, deterministic=True, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample = np.concatenate(x_reconst[:10,0].detach().cpu().numpy(), axis=1)\n",
    "input_sample = np.concatenate(data[:10,0].detach().cpu().numpy(), axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb359df1",
   "metadata": {},
   "source": [
    "## Training on SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25fe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model_2 import VAEClassifier, StAEClassifier\n",
    "epoch_num = 100\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.SVHN(root='./data', split='train', download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])), batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3960c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_classifier = VAEClassifier()\n",
    "stae_classifier = StAEClassifier()\n",
    "vae_classifier = VAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "stae_classifier = StAEClassifier(num_feature_map=64,encoder_layer=3,decoder_layers=4,input_channels=3).to(device)\n",
    "\n",
    "CE_Loss = nn.CrossEntropyLoss()\n",
    "mseloss = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(vae_classifier.parameters(), lr=lr)\n",
    "optimizer2 = torch.optim.Adam(stae_classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21843da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "for epoch in range(epoch_num):\n",
    "    vae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y, mu, log_var = vae_classifier(data, deterministic=False, classification_only=False)\n",
    "        recons_loss = torch.sum((x_reconst - data) ** 2)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp()) \n",
    "        # jointly training\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + recons_loss + kld_loss \n",
    "        optimizer1.zero_grad() \n",
    "        loss_val.backward() \n",
    "        optimizer1.step() \n",
    "\n",
    "vae_classifier.eval()\n",
    "torch.save(vae_classifier.state_dict(), './svhn_vae_clf.pth')\n",
    "# St-AE\n",
    "for epoch in range(epoch_num):\n",
    "    stae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y = stae_classifier(data, classification_only=False)\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + torch.sum((x_reconst - data) ** 2)\n",
    "        optimizer2.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "stae_classifier.eval()\n",
    "torch.save(stae_classifier.state_dict(), './svhn_stae_clf.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7190418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.SVHN(root='./data', split='test', download=True,transform=transforms.Compose([\n",
    "        transforms.ToTensor(),])), batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6889bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# St-AE\n",
    "pred_list = []\n",
    "gt_list = [] # ground truth\n",
    "for batch_idx, (data, target) in enumerate(test_loader): \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test = stae_classifier(data, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample_np = np.transpose(x_reconst[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "input_sample_np = np.transpose(data[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "reconst_sample = np.concatenate(reconst_sample_np, axis=1)\n",
    "input_sample = np.concatenate(input_sample_np, axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0))\n",
    "plt.show()\n",
    "# VAE\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test, mu, log_var = vae_classifier(data, deterministic=True, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample_np = np.transpose(x_reconst[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "input_sample_np = np.transpose(data[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "reconst_sample = np.concatenate(reconst_sample_np, axis=1)\n",
    "input_sample = np.concatenate(input_sample_np, axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53779785",
   "metadata": {},
   "source": [
    "## Training on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a939021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model_cifar10 import VAEClassifier, StAEClassifier\n",
    "epoch_num = 200\n",
    "# Training dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])), batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_classifier = VAEClassifier()\n",
    "stae_classifier = StAEClassifier()\n",
    "vae_classifier = vae_classifier.to(device) \n",
    "stae_classifier = stae_classifier.to(device)\n",
    "CE_Loss = nn.CrossEntropyLoss()\n",
    "mseloss = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(vae_classifier.parameters(), lr=lr)\n",
    "optimizer2 = torch.optim.Adam(stae_classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "for epoch in range(epoch_num):\n",
    "    vae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y, mu, log_var = vae_classifier(data, deterministic=False, classification_only=False)\n",
    "        recons_loss = torch.sum((x_reconst - data) ** 2)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp()) \n",
    "        # jointly training\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + recons_loss + kld_loss \n",
    "        optimizer1.zero_grad() \n",
    "        loss_val.backward() \n",
    "        optimizer1.step() \n",
    "\n",
    "vae_classifier.eval()\n",
    "torch.save(vae_classifier.state_dict(), './cifar10_vae_clf.pth')\n",
    "# St-AE\n",
    "for epoch in range(epoch_num):\n",
    "    stae_classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        x_reconst, z, y = stae_classifier(data, classification_only=False)\n",
    "        loss_val = CE_Loss(y, target) * classification_weight * batch_size + torch.sum((x_reconst - data) ** 2)\n",
    "        optimizer2.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "stae_classifier.eval()\n",
    "torch.save(stae_classifier.state_dict(), './cifar10_stae_clf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),])), batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# St-AE\n",
    "pred_list = []\n",
    "gt_list = [] # ground truth\n",
    "for batch_idx, (data, target) in enumerate(test_loader): \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test = stae_classifier(data, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample_np = np.transpose(x_reconst[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "input_sample_np = np.transpose(data[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "reconst_sample = np.concatenate(reconst_sample_np, axis=1)\n",
    "input_sample = np.concatenate(input_sample_np, axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0))\n",
    "plt.show()\n",
    "# VAE\n",
    "pred_list = []\n",
    "gt_list = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    x_reconst, z, y_test, mu, log_var = vae_classifier(data, deterministic=True, classification_only=False)\n",
    "    pred_list += list(y_test.argmax(-1).cpu().detach().numpy())\n",
    "    gt_list += list(target.detach().cpu().numpy())\n",
    "acc = np.sum(np.array(gt_list) == np.array(pred_list)) / len(gt_list)\n",
    "print(acc)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "reconst_sample_np = np.transpose(x_reconst[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "input_sample_np = np.transpose(data[:10].detach().cpu().numpy(), (0, 2, 3, 1))\n",
    "reconst_sample = np.concatenate(reconst_sample_np, axis=1)\n",
    "input_sample = np.concatenate(input_sample_np, axis=1)\n",
    "plt.imshow(np.concatenate([input_sample, reconst_sample], axis=0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xmyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
